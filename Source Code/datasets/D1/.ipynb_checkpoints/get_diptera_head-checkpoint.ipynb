{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm for downloading images from iDigBio\n",
    "###  (all images are verified by experts)\n",
    "\n",
    "All Diptera occurences from iDigBio are obtained and cleaned to preserve only those that have associated image of the frontal view (head) of the specimens.\n",
    "\n",
    "### NOTE: to download the same images as in our study use this csv file \n",
    "\n",
    "    D1_list_of_filtered_images.csv\n",
    "    \n",
    "### Here is the walk trough how we acquired and filtered the images\n",
    "\n",
    "**Input**: multimedia.csv - a list of records from iDigBio obtained with query keywords (\"hasImage\":\"true\" and \"order\":\"diptera\")\n",
    "\n",
    "**Outputs**: images of frontal habitus sorted by family names\n",
    "\n",
    "Procedure: \n",
    "\n",
    "\tStep 1.\n",
    "\t\tcollect:\n",
    "\t\t\t- images with keywords\n",
    "\t\t\t\t- 'dorsal'\n",
    "\t\t\t\t- 'habitus_dor', 'Habitus_dor'\n",
    "\t\t\t\t- '_D.', \"_had\"\n",
    "\t\t\t- images from institutions that provide mainly dorsal view \n",
    "\t\t\t\t- 'Denver Museum of Nature & Science'\n",
    "\t            - 'University of Tennessee at Chattanooga (UTC-UTCI)'\n",
    "\t            - 'United States National Museum, Entomology Collections (USNM-USNMENT)'\n",
    "\t\tskip: \n",
    "\t\t\t- images with keywords: \n",
    "\t\t\t\t- \"lateral\", \"frontal\", \"ventral\", 'anterior'\n",
    "\t\t\t\t- \"head\", 'antenna', \"labels\", \n",
    "\t\t\t\t- 'mesosoma', \"genitalia\"\n",
    "\t\t\t\t- \"_L\", \"_F\", \"_V\", \n",
    "\t\t\t\t- 'web', 'habitus_lat', 'Habitus_lat' \n",
    "\t\t\t\t- \"hed\", \"hef\", \"hal\", \"hed\" (head images) \n",
    "            - images from institutions that provided fossil images\n",
    "\t\tcheck:\n",
    "\t\t\t- from records that are not skipped or collected depict images from poorly represented families \n",
    "\tStep 2.\n",
    "    \t- download images from families with N+ records\n",
    "\t\t- manually check all the images (to avoid drawings, images of labels, images where head is destroyed, etc.)\n",
    "        \n",
    "\n",
    "We ended up with 11 families and 884 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('metadata/multimedia_raw.csv', 'rt') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    total_media = 0\n",
    "    remained = []\n",
    "    cleaned_list = []\n",
    "    first_row = []\n",
    "    #iterate over each row and count how many they are\n",
    "    for row in reader:\n",
    "        if first_row == []:\n",
    "            first_row = row\n",
    "    \n",
    "        total_media +=1\n",
    "\n",
    "        # and clean row 100 - some institutions provided only photos of labels with insects barelly visible or fossils\n",
    "        # Arizona, Hawaii, Yale, Michigan, Texas\n",
    "        \n",
    "        if row[100] == 'University of Hawaii Insect Museum' or\\\n",
    "            row[100] == 'University of California Museum of Paleontology' or\\\n",
    "            row[100] == 'CUML' or\\\n",
    "            row[54]  == 'Michigan State University' or\\\n",
    "            row[54] == 'University of Minnesota' or\\\n",
    "            row[100] == 'Queensland Museum' or\\\n",
    "            row[100] == 'something':\n",
    "            pass\n",
    "        \n",
    "        # Colorado\n",
    "        elif row[100]== 'Colorado Plateau Museum of Arthropod Biodiversity (NAUF-CPMAB)' and '_F.' in row[15]:\n",
    "            cleaned_list.append(row)    \n",
    "        elif row[100]== 'Colorado Plateau Museum of Arthropod Biodiversity (NAUF-CPMAB)':\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # HARVARD\n",
    "        elif 'Harvard University' in row[100] and '_hef' in row[5]:\n",
    "            cleaned_list.append(row)    \n",
    "        elif row[100]== 'Museum of Comparative Zoology, Harvard University':\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # also to exclude fossils, audio media, slides, drawers, broken links, no access\n",
    "        elif 'PALE' in row[5] or \\\n",
    "            'macaulay' in row[15] or\\\n",
    "            'flickr' in row[5] or\\\n",
    "            'invert' in row[5] or\\\n",
    "            'utexas' in row[5] or\\\n",
    "            'osuc' in row[5] or\\\n",
    "            'yale' in row[5]: \n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # get rid the images which are reported as not dorsal view    \n",
    "        elif 'Later' in row[29] or\\\n",
    "            'Dors' in row[29] or\\\n",
    "            'Tho' in row[30] or 'Gen' in row[30] or 'Whol' in row[30] or 'Ventr' in row[29]:\n",
    "            pass   \n",
    "        \n",
    "        elif 'Head' in row[30]:\n",
    "            cleaned_list.append(row)\n",
    "        \n",
    "        # how many images are not treated\n",
    "        else:   \n",
    "            remained.append(row)\n",
    "            \n",
    "\n",
    "print ('true\\t\\t', len(cleaned_list))\n",
    "print ('cleaned\\t\\t', total_media- len(cleaned_list)- len(remained))\n",
    "print\n",
    "print ('remained to treat\\t', len(remained))\n",
    "print ('total data\\t\\t', total_media)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### next, we checked institutions which we still have to treat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "to_treat={}\n",
    "for row in remained:\n",
    "    if row[100] in to_treat.keys():\n",
    "        to_treat[row[100]]+=1\n",
    "    else:\n",
    "        to_treat[row[100]]=1\n",
    "for key in to_treat:\n",
    "    print (to_treat[key], key, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOT IN USE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#the cell bellow is used to show links for untreated images provided by certain institution\n",
    "num = 0\n",
    "for row in remained:\n",
    "    if 'arctos' in row[5]:\n",
    "        num+=1\n",
    "        print (row[5])\n",
    "print (num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the list as csv file and add the titles in the first row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaned_list.insert(0, first_row)\n",
    "\n",
    "with open('metadata/newcleaned_head.csv', 'wt') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    for row in range(len(cleaned_list)):\n",
    "        wr.writerow(cleaned_list[row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remained.insert(0, first_row)\n",
    "with open('metadata/newremained.csv', 'wt') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    for row in range(len(remained)):\n",
    "        wr.writerow(remained[row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# download the images \n",
    "from **cleaned_head.csv** and if you wish add manually more examples  from **remained.csv** for families with fewer examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all(records, dictionary, save_to, tax_level = 'family', num=25):\n",
    "    if tax_level == 'genus':\n",
    "        level = 4\n",
    "    else:\n",
    "        level = 3\n",
    "    for key in dictionary.keys():\n",
    "        if len(dictionary[key])>num:\n",
    "            print ()\n",
    "            print (len(dictionary[key]), key)\n",
    "            print()\n",
    "            directory = save_to + '/' + key\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            for value in dictionary[key]:\n",
    "                for i in records:\n",
    "                    if value == i[0]:\n",
    "                        print (i[level])\n",
    "                        urllib.urlretrieve(i[1], directory+'/'+i[2]+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D1_list_of_filtered_images.csv', 'rt') as csv1:\n",
    "    dorsal = csv.reader(csv1)\n",
    "    records = []\n",
    "    record = []\n",
    "    for row in dorsal:\n",
    "        records.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_all(records, family, 'family', num=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make sure you examine and clean your dataset manually\n",
    "\n",
    "### or you can simply download filtered images a list we provided \n",
    "\n",
    "    D1_list_of_filtered_images.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (SpiderTree)",
   "language": "python",
   "name": "pycharm-98a829c8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
